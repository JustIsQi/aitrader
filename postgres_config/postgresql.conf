# PostgreSQL Optimized Configuration for Analytical Workloads
# System: 1008GB RAM
# Purpose: Stock market data analysis with large time-series queries

# =============================================================================
# MEMORY SETTINGS (Analytical Workload Optimization)
# =============================================================================

# shared_buffers: 25% of RAM for caching frequently accessed data
# Default: 128MB (0.01% of RAM) → Optimized: 256GB (25% of RAM)
shared_buffers = 256GB

# work_mem: Per-operation memory for sorts, hash tables, etc.
# Default: 4MB → Optimized: 256MB (supports large analytical operations)
work_mem = 256MB

# maintenance_work_mem: Memory for maintenance operations (VACUUM, CREATE INDEX, etc.)
# Default: 64MB → Optimized: 8GB (speeds up index creation and bulk loads)
maintenance_work_mem = 8GB

# effective_cache_size: Estimation of OS cache + shared_buffers
# Default: 4GB → Optimized: 756GB (75% of RAM for accurate query planning)
effective_cache_size = 756GB

# =============================================================================
# PARALLEL QUERY SETTINGS
# =============================================================================

# max_worker_processes: Total background worker processes
# Default: 8 → Optimized: 32 (supports more parallel operations)
max_worker_processes = 32

# max_parallel_workers_per_gather: Max parallel workers per single query
# Default: 2 → Optimized: 8 (dramatically improves analytical query performance)
max_parallel_workers_per_gather = 8

# max_parallel_workers: Total parallel workers across all queries
# Default: 8 → Optimized: 32 (match max_worker_processes)
max_parallel_workers = 32

# parallel_tuple_cost: Cost per tuple for parallel execution
# Default: 0.1 → Optimized: 0.01 (encourage parallel execution)
parallel_tuple_cost = 0.01

# parallel_setup_cost: Setup cost for parallel workers
# Default: 1000 → Optimized: 100 (reduce penalty for parallel setup)
parallel_setup_cost = 100.0

# =============================================================================
# QUERY OPTIMIZATION (SSD Storage)
# =============================================================================

# random_page_cost: Cost of non-sequentially fetched disk page
# Default: 4.0 (HDD) → Optimized: 1.1 (SSD/NVMe)
random_page_cost = 1.1

# seq_page_cost: Cost of sequentially fetched disk page
# Default: 1.0 → Optimized: 1.0 (keep default)
seq_page_cost = 1.0

# effective_io_concurrency: Number of simultaneous I/O requests
# Default: 16 → Optimized: 200 (better for SSD/NVMe with high throughput)
effective_io_concurrency = 200

# maintenance_io_concurrency: I/O concurrency for maintenance operations
maintenance_io_concurrency = 200

# =============================================================================
# CONNECTION SETTINGS
# =============================================================================

# max_connections: Maximum concurrent connections
# Default: 100 → Optimized: 200 (supports higher concurrency)
max_connections = 200

# =============================================================================
# WAL CONFIGURATION (Optimized for Bulk Loading)
# =============================================================================

# wal_level: Write-Ahead Logging level
# Keep default: replica (required for replication)
wal_level = replica

# max_wal_size: Maximum WAL size before automatic checkpoint
# Default: 1GB → Optimized: 4GB (reduces checkpoint frequency during bulk loads)
max_wal_size = 4GB

# min_wal_size: Minimum WAL size
# Default: 80MB → Keep default
min_wal_size = 80MB

# checkpoint_timeout: Time between automatic WAL checkpoints
# Default: 5min → Optimized: 15min (reduces checkpoint overhead)
checkpoint_timeout = 15min

# checkpoint_completion_target: Target for checkpoint completion
# Default: 0.9 → Keep default (smooth checkpoints)
checkpoint_completion_target = 0.9

# =============================================================================
# QUERY PLANNER SETTINGS
# =============================================================================

# jit: Just-In-Time compilation
# Default: on → Keep enabled
jit = on

# jit_above_cost: Cost threshold for JIT compilation
# Default: 100000 → Optimized: 50000 (enable JIT for more queries)
jit_above_cost = 50000

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================

# Log slow queries (> 1 second)
log_min_duration_statement = 1000

# Log line prefix format
log_line_prefix = '%t [%p] %u@%d '

# Track I/O timing for EXPLAIN ANALYZE
track_io_timing = on

# Track function call timing
track_functions = all

# =============================================================================
# AUTOVACUUM SETTINGS
# =============================================================================

# autovacuum_max_workers: Maximum number of autovacuum workers
# Default: 3 → Optimized: 4 (better for large tables)
autovacuum_max_workers = 4

# =============================================================================
# NOTES
# =============================================================================
#
# This configuration is optimized for:
# - Large analytical queries on time-series data
# - Parallel query execution (8 workers per query)
# - High memory system (1008GB RAM)
# - SSD/NVMe storage
# - Concurrent strategy runs (multiple backtests)
#
# Expected improvements:
# - 5-10x faster analytical queries through parallel execution
# - 2-3x faster data loading through optimized caching
# - Support for 10+ concurrent strategy runs
#
# To apply this configuration:
# 1. Stop current PostgreSQL container
# 2. Start new container with this config mounted
# 3. Verify settings: SHOW shared_buffers;
