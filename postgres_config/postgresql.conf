# PostgreSQL Optimized Configuration for Analytical Workloads
# System: 4-core CPU, 8GB RAM
# Purpose: Stock market data analysis with time-series queries
# Updated: 2026-01-13 (Optimized for 4C8G server)

# =============================================================================
# MEMORY SETTINGS (8GB RAM System)
# =============================================================================

# shared_buffers: 25% of RAM for caching frequently accessed data
# Default: 128MB → Optimized: 2GB (25% of 8GB RAM, optimal for mixed workload)
shared_buffers = 2GB

# work_mem: Per-operation memory for sorts, hash tables, aggregates
# Formula: (RAM - shared_buffers) / max_connections / 3
# Default: 4MB → Optimized: 16MB (conservative for 100 connections)
work_mem = 16MB

# maintenance_work_mem: Memory for maintenance operations (VACUUM, CREATE INDEX, etc.)
# Default: 64MB → Optimized: 512MB (speeds up maintenance without oversizing)
maintenance_work_mem = 512MB

# effective_cache_size: Estimation of OS cache + shared_buffers
# Default: 4GB → Optimized: 6GB (75% of RAM for accurate query planning)
effective_cache_size = 6GB

# =============================================================================
# PARALLEL QUERY SETTINGS (4-core CPU)
# =============================================================================

# max_worker_processes: Total background worker processes (autovacuum + parallel)
# Default: 8 → Optimized: 4 (match CPU cores)
max_worker_processes = 4

# max_parallel_workers_per_gather: Max parallel workers per single query
# Default: 2 → Optimized: 2 (leave 2 cores for other operations)
max_parallel_workers_per_gather = 2

# max_parallel_workers: Total parallel workers across all queries
# Default: 8 → Optimized: 4 (match max_worker_processes)
max_parallel_workers = 4

# parallel_tuple_cost: Cost per tuple for parallel execution
# Default: 0.1 → Optimized: 0.01 (encourage parallel execution)
parallel_tuple_cost = 0.01

# parallel_setup_cost: Setup cost for parallel workers
# Default: 1000 → Optimized: 100 (reduce penalty for parallel setup)
parallel_setup_cost = 100.0

# =============================================================================
# QUERY OPTIMIZATION (HDD Storage)
# =============================================================================

# random_page_cost: Cost of non-sequentially fetched disk page
# Default: 4.0 (HDD) → Optimized: 2.0 (HDD with rotational storage)
random_page_cost = 2.0

# seq_page_cost: Cost of sequentially fetched disk page
# Default: 1.0 → Keep default
seq_page_cost = 1.0

# effective_io_concurrency: Number of simultaneous I/O requests
# Default: 16 → Optimized: 2 (HDD optimization)
effective_io_concurrency = 2

# maintenance_io_concurrency: I/O concurrency for maintenance operations
maintenance_io_concurrency = 2

# =============================================================================
# CONNECTION SETTINGS
# =============================================================================

# max_connections: Maximum concurrent connections
# Default: 100 → Optimized: 100 (reduce from 200 to save memory)
max_connections = 100

# =============================================================================
# WAL CONFIGURATION (Optimized for Bulk Loading)
# =============================================================================

# wal_level: Write-Ahead Logging level
# Keep default: replica (required for replication)
wal_level = replica

# max_wal_size: Maximum WAL size before automatic checkpoint
# Default: 1GB → Optimized: 2GB (reduce disk usage on smaller system)
max_wal_size = 2GB

# min_wal_size: Minimum WAL size
# Default: 80MB → Keep default
min_wal_size = 80MB

# checkpoint_timeout: Time between automatic WAL checkpoints
# Default: 5min → Optimized: 10min (balance performance and recovery time)
checkpoint_timeout = 10min

# checkpoint_completion_target: Target for checkpoint completion
# Default: 0.9 → Keep default (smooth checkpoints)
checkpoint_completion_target = 0.9

# =============================================================================
# QUERY PLANNER SETTINGS
# =============================================================================

# jit: Just-In-Time compilation
# Default: on → Keep enabled
jit = on

# jit_above_cost: Cost threshold for JIT compilation
# Default: 100000 → Optimized: 50000 (enable JIT for more queries)
jit_above_cost = 50000

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================

# Log slow queries (> 2 seconds for slower hardware)
log_min_duration_statement = 2000

# Log line prefix format
log_line_prefix = '%t [%p] %u@%d '

# Track I/O timing for EXPLAIN ANALYZE
track_io_timing = on

# Track function call timing
track_functions = all

# =============================================================================
# AUTOVACUUM SETTINGS
# =============================================================================

# autovacuum_max_workers: Maximum number of autovacuum workers
# Default: 3 → Optimized: 4 (better for large tables)
autovacuum_max_workers = 4

# =============================================================================
# NOTES
# =============================================================================
#
# This configuration is optimized for:
# - 4-core CPU, 8GB RAM system
# - Mixed workload: Web API + batch backtesting + signal generation
# - HDD storage (rotational media)
# - Time-series analytical queries on stock market data
# - 100-1000 stocks per operation
#
# Expected performance:
# - Stable operation without OOM errors
# - 2-3x faster queries through proper memory allocation
# - Support for 2 concurrent backtests (1.5-2GB each)
# - Reduced I/O wait through better caching
#
# Hardware upgrade recommendations (priority order):
# 1. SSD upgrade: 5-10x I/O improvement (~$50-100)
# 2. RAM upgrade to 16GB: 2-3x throughput improvement (~$30-50)
# 3. CPU upgrade to 8 cores: 1.5-2x compute improvement (~$100-200)
#
# To apply this configuration:
# 1. Stop current PostgreSQL container: docker stop pg
# 2. Start new container with this config mounted
# 3. Verify settings: docker exec pg psql -U postgres -c "SHOW shared_buffers;"
