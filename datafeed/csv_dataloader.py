from datetime import datetime

import pandas as pd
from loguru import logger

from config import DATA_DIR

# æ˜¯å¦å¯ç”¨ DuckDB ä½œä¸ºæ•°æ®æº
ENABLE_DUCKDB = True
DUCKDB_PATH = '/data/home/yy/data/duckdb/trading.db'


class CsvDataLoader:
    def __init__(self, auto_download=True, use_duckdb=None):
        """
        Args:
            auto_download: æ˜¯å¦è‡ªåŠ¨ä¸‹è½½ç¼ºå¤±çš„æ•°æ®
            use_duckdb: æ˜¯å¦ä½¿ç”¨ DuckDB ä½œä¸ºæ•°æ®æºï¼ˆNone è¡¨ç¤ºæ ¹æ®å…¨å±€é…ç½®ï¼‰
        """
        self.auto_download = auto_download
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨ DuckDB
        if use_duckdb is None:
            self.use_duckdb = ENABLE_DUCKDB
        else:
            self.use_duckdb = use_duckdb

        # å¦‚æœå¯ç”¨ DuckDBï¼Œåˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self.db = None
        if self.use_duckdb:
            try:
                from database.db_manager import get_db
                self.db = get_db(DUCKDB_PATH)
                logger.info('CsvDataLoader: ä½¿ç”¨ DuckDB ä½œä¸ºæ•°æ®æº')
            except Exception as e:
                logger.warning(f'DuckDB åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° CSV æ¨¡å¼: {e}')
                self.use_duckdb = False

    def _download_to_duckdb(self, symbol):
        """ä¸‹è½½æ•°æ®å¹¶ç›´æ¥å†™å…¥DuckDBï¼Œä¸ä¿å­˜CSVæ–‡ä»¶"""
        try:
            from scripts.get_data import is_etf, fetch_stock_history_with_proxy, fetch_etf_history, fetch_stock_history
            import akshare as ak

            logger.info(f'ğŸ”„ [DuckDB] å¼€å§‹ä¸‹è½½ {symbol} æ•°æ®...')

            # åˆ¤æ–­æ˜¯ETFè¿˜æ˜¯è‚¡ç¥¨
            if is_etf(symbol):
                code = symbol.split('.')[0]
                logger.info(f'ğŸ“Š [DuckDB] {symbol} è¯†åˆ«ä¸º ETFï¼Œä»£ç : {code}')
                df = fetch_stock_history_with_proxy(code, func=fetch_etf_history)
            else:
                code = symbol.split('.')[0]
                logger.info(f'ğŸ“Š [DuckDB] {symbol} è¯†åˆ«ä¸ºè‚¡ç¥¨ï¼Œä»£ç : {code}')
                df = fetch_stock_history_with_proxy(code, func=fetch_stock_history)

            if df is None or df.empty:
                logger.error(f'âŒ [DuckDB] è·å– {symbol} æ•°æ®ä¸ºç©º')
                return None

            logger.info(f'âœ“ [DuckDB] {symbol} åŸå§‹æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•')

            # è½¬æ¢åˆ—åä¸ºè‹±æ–‡
            if 'æ—¥æœŸ' in df.columns:
                df.rename(columns={'æ—¥æœŸ': 'date', 'è‚¡ç¥¨ä»£ç ': 'symbol',
                                   'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close',
                                   'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                                   'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount',
                                   'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount',
                                   'æŒ¯å¹…': 'amplitude', 'æ¢æ‰‹ç‡': 'turnover_rate'}, inplace=True)
                logger.debug(f'ğŸ“ [DuckDB] {symbol} åˆ—åå·²è½¬æ¢ä¸ºè‹±æ–‡')

            # æ·»åŠ  symbol åˆ—
            df['symbol'] = symbol

            # æ˜¾ç¤ºæ•°æ®èŒƒå›´
            if 'date' in df.columns:
                date_range = f"{df['date'].min()} ~ {df['date'].max()}"
                logger.info(f'ğŸ“… [DuckDB] {symbol} æ•°æ®æ—¥æœŸèŒƒå›´: {date_range}')

            # ç›´æ¥å†™å…¥ DuckDB
            logger.info(f'ğŸ’¾ [DuckDB] æ­£åœ¨å†™å…¥ {symbol} æ•°æ®åˆ°æ•°æ®åº“...')
            if is_etf(symbol):
                success = self.db.insert_etf_history(df, symbol)
                table_name = 'etf_history'
            else:
                success = self.db.insert_stock_history(df, symbol)
                table_name = 'stock_history'

            if success:
                logger.info(f'âœ… [DuckDB] {symbol} æ•°æ®å·²æˆåŠŸå†™å…¥è¡¨ {table_name}: {df.shape}')
            else:
                logger.error(f'âŒ [DuckDB] {symbol} æ•°æ®å†™å…¥å¤±è´¥')

            return df if success else None

        except Exception as e:
            logger.error(f'âŒ [DuckDB] ä¸‹è½½ {symbol} åˆ°æ•°æ®åº“å¤±è´¥: {e}')
            import traceback
            logger.debug(f'ğŸ” [DuckDB] é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}')
            return None

    def _read_csv(self, symbol, path='akshare_data'):
        # æ”¯æŒ akshare_data æ ¼å¼: ä»£ç _history.csv
        csv = DATA_DIR.joinpath(path).joinpath('{}_history.csv'.format(symbol))
        if not csv.exists():
            if self.auto_download:
                # å¦‚æœå¯ç”¨äº† DuckDBï¼Œç›´æ¥å†™å…¥æ•°æ®åº“ï¼Œä¸ä¿å­˜ CSV
                if self.use_duckdb and self.db:
                    logger.warning(f'{csv.resolve()} ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½åˆ° DuckDB...')
                    df = self._download_to_duckdb(symbol)
                    if df is not None:
                        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸º YYYYMMDDï¼ˆç§»é™¤æ¨ªæ ï¼‰
                        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y%m%d')
                        df['symbol'] = symbol
                        df.dropna(inplace=True)
                        return df
                    else:
                        logger.error(f'ä¸‹è½½ {symbol} æ•°æ®å¤±è´¥')
                        return None
                else:
                    # åŸæœ‰é€»è¾‘ï¼šä¸‹è½½åˆ° CSV
                    logger.warning(f'{csv.resolve()} ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½...')
                    from scripts.get_data import download_symbol_data
                    success = download_symbol_data(symbol)
                    if not success:
                        logger.error(f'ä¸‹è½½ {symbol} æ•°æ®å¤±è´¥')
                        return None
                    # ä¸‹è½½æˆåŠŸåé‡æ–°è¯»å–
                    if not csv.exists():
                        logger.error(f'ä¸‹è½½åæ–‡ä»¶ä»ä¸å­˜åœ¨: {csv.resolve()}')
                        return None
            else:
                logger.warning('{}ä¸å­˜åœ¨'.format(csv.resolve()))
                return None

        df = pd.read_csv(csv.resolve(), index_col=None)

        # akshare æ ¼å¼ä½¿ç”¨ä¸­æ–‡åˆ—å"æ—¥æœŸ"ï¼Œè½¬æ¢ä¸º"date"
        if 'æ—¥æœŸ' in df.columns:
            df.rename(columns={'æ—¥æœŸ': 'date', 'è‚¡ç¥¨ä»£ç ': 'symbol',
                               'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close',
                               'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                               'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount'}, inplace=True)
        else:
            # åŸæœ‰æ ¼å¼å¤„ç†
            df['date'] = df['date'].apply(lambda x: str(x))

        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸º YYYYMMDDï¼ˆç§»é™¤æ¨ªæ ï¼‰
        df['date'] = df['date'].astype(str).str.replace('-', '')

        df['symbol'] = symbol
        df.dropna(inplace=True)
        return df

    def _read_duckdb(self, symbol, start_date, end_date):
        """ä» DuckDB è¯»å–æ•°æ®"""
        try:
            if not self.db:
                raise Exception("DuckDB æœªåˆå§‹åŒ–")

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            start_date_fmt = start_date[:4] + '-' + start_date[4:6] + '-' + start_date[6:]
            end_date_fmt = end_date[:4] + '-' + end_date[4:6] + '-' + end_date[6:]

            # åˆ¤æ–­æ˜¯ETFè¿˜æ˜¯è‚¡ç¥¨
            from scripts.get_data import is_etf
            if is_etf(symbol):
                df = self.db.get_etf_history(symbol, start_date=start_date_fmt, end_date=end_date_fmt)
            else:
                df = self.db.get_stock_history(symbol, start_date=start_date_fmt, end_date=end_date_fmt)

            if df.empty:
                logger.info(f'DuckDB ä¸­æ—  {symbol} æ•°æ®ï¼Œå¼€å§‹ä¸‹è½½...')
                # å°è¯•ä¸‹è½½æ•°æ®åˆ° DuckDB
                if self.auto_download:
                    df = self._download_to_duckdb(symbol)
                    if df is not None:
                        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸º YYYYMMDDï¼ˆç§»é™¤æ¨ªæ ï¼‰
                        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y%m%d')
                        df['symbol'] = symbol
                        df.dropna(inplace=True)
                        return df
                logger.warning(f'DuckDB ä¸­æ—  {symbol} æ•°æ®')
                return None

            # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸º YYYYMMDD
            df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y%m%d')

            # æ·»åŠ  symbol åˆ—
            df['symbol'] = symbol

            df.dropna(inplace=True)
            return df

        except Exception as e:
            logger.error(f'ä» DuckDB è¯»å– {symbol} å¤±è´¥: {e}')
            return None

    def read_dfs(self, symbols: list[str], path='akshare_data', start_date='20100101', end_date=datetime.now().strftime('%Y%m%d')):
        dfs = {}

        for s in symbols:
            # ä½¿ç”¨ DuckDB æ¨¡å¼
            if self.use_duckdb:
                df = self._read_duckdb(s, start_date, end_date)
                if df is not None:
                    dfs[s] = df
                    continue
                # DuckDB è¯»å–å¤±è´¥ï¼ˆåŒ…æ‹¬ä¸‹è½½å¤±è´¥ï¼‰
                logger.error(f'æ— æ³•è·å– {s} çš„æ•°æ®ï¼Œå·²å°è¯•è‡ªåŠ¨ä¸‹è½½ä½†å¤±è´¥')
                continue

            # ä½¿ç”¨ CSV æ¨¡å¼ï¼ˆé DuckDBï¼‰
            df = self._read_csv(s, path=path)
            if df is None:
                logger.warning(f'æ•°æ®æ–‡ä»¶ {s} ä¸å­˜åœ¨ï¼Œè·³è¿‡')
                continue

            # akshare æ•°æ®å·²ç»æ˜¯å‡åºï¼Œæ— éœ€æ’åº
            # df.sort_values(by='date', ascending=True, inplace=True)

            if df['date'].iloc[0] > start_date:
                start_date = df['date'].iloc[0]
            df = df[df['date'] >= start_date]
            df = df[df['date'] <= end_date]

            dfs[s] = df

        if not dfs:
            missing_symbols = [s for s in symbols if s not in dfs]
            raise ValueError(f"æ²¡æœ‰å¯ç”¨çš„æ•°æ®ã€‚ä»¥ä¸‹æ ‡çš„æ•°æ®ç¼ºå¤±: {missing_symbols}ã€‚å·²å°è¯•è‡ªåŠ¨ä¸‹è½½ä½†ä»å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä»£ç†è®¾ç½®ã€‚")

        print('å¼€å§‹æ—¥æœŸ', start_date)

        for s in dfs.keys():
            df = dfs[s]
            df = df[df['date'] >= start_date]
            df = df[df['date'] <= end_date]

            dfs[s] = df
        return dfs

    def read_df(self, symbols: list[str], start_date='20100101', end_date=datetime.now().strftime('%Y%m%d'),
                path='akshare_data'):
        dfs = []
        for s in symbols:
            df = self._read_csv(s, path=path)
            if df is not None:
                dfs.append(df)

        if not dfs:
            return pd.DataFrame()

        df = pd.concat(dfs, axis=0)
        # akshare æ•°æ®å·²ç»æ˜¯å‡åºï¼Œæ— éœ€æ’åº
        # df.sort_values(by='date', ascending=True, inplace=True)
        df = df[df['date'] >= start_date]
        df = df[df['date'] <= end_date]

        return df

if __name__ == '__main__':
    df = CsvDataLoader().read_df(symbols=['510300.SH','159915.SZ'])
    print(df)